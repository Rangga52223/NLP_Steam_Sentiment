{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'train_rev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.1', 'Unnamed: 0', 'review', 'recommendation', 'game_name'], dtype='object')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['review'].values\n",
    "\n",
    "y2 = df['game_name'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['recommendation'] = label_encoder.fit_transform(df['recommendation'])  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "unique_values = df['recommendation'].unique()\n",
    "print(unique_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = df['recommendation'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Panjang persentil ke-90: 211.0\n",
      "Panjang maxlen yang digunakan: 211\n"
     ]
    }
   ],
   "source": [
    "df['length'] = df['review'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Tentukan nilai persentil ke-90 dari panjang review\n",
    "percentile_90 = np.percentile(df['length'], 90)\n",
    "print(f'Panjang persentil ke-90: {percentile_90}')\n",
    "\n",
    "# Gunakan nilai ini sebagai maxlen\n",
    "maxlen = int(percentile_90)\n",
    "print(f'Panjang maxlen yang digunakan: {maxlen}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat Tokenizer\n",
    "tokenizer = Tokenizer(num_words=2000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X)\n",
    "\n",
    "# Mengonversi teks menjadi urutan\n",
    "sequences = tokenizer.texts_to_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(X)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen=211\n",
    "padded_sequences = pad_sequences(sequences, maxlen=maxlen, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "unique_values = df['recommendation'].unique()\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train1, y_test1= train_test_split(padded_sequences, y1, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\Documents\\projek\\Steam_pred\\bakso2\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m466/466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 160ms/step - accuracy: 0.5175 - loss: 0.6904 - val_accuracy: 0.5385 - val_loss: 0.6833\n",
      "Epoch 2/10\n",
      "\u001b[1m466/466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 184ms/step - accuracy: 0.5260 - loss: 0.6805 - val_accuracy: 0.5396 - val_loss: 0.6814\n",
      "Epoch 3/10\n",
      "\u001b[1m466/466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 199ms/step - accuracy: 0.5446 - loss: 0.6634 - val_accuracy: 0.5380 - val_loss: 0.6867\n",
      "Epoch 4/10\n",
      "\u001b[1m466/466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 212ms/step - accuracy: 0.5576 - loss: 0.6528 - val_accuracy: 0.5490 - val_loss: 0.6986\n",
      "Epoch 5/10\n",
      "\u001b[1m466/466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 210ms/step - accuracy: 0.5728 - loss: 0.6442 - val_accuracy: 0.6768 - val_loss: 0.6505\n",
      "Epoch 6/10\n",
      "\u001b[1m466/466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 207ms/step - accuracy: 0.7043 - loss: 0.5717 - val_accuracy: 0.6719 - val_loss: 0.6619\n",
      "Epoch 7/10\n",
      "\u001b[1m466/466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 225ms/step - accuracy: 0.7058 - loss: 0.5644 - val_accuracy: 0.6244 - val_loss: 0.6328\n",
      "Epoch 8/10\n",
      "\u001b[1m466/466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 256ms/step - accuracy: 0.7479 - loss: 0.5168 - val_accuracy: 0.7726 - val_loss: 0.5251\n",
      "Epoch 9/10\n",
      "\u001b[1m466/466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 260ms/step - accuracy: 0.8169 - loss: 0.4348 - val_accuracy: 0.7997 - val_loss: 0.4887\n",
      "Epoch 10/10\n",
      "\u001b[1m466/466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 233ms/step - accuracy: 0.8433 - loss: 0.3944 - val_accuracy: 0.8070 - val_loss: 0.4712\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - accuracy: 0.8126 - loss: 0.4632\n",
      "Test accuracy: 0.81\n"
     ]
    }
   ],
   "source": [
    "s=2000\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=s, output_dim=128, input_length=maxlen))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Untuk binary classification\n",
    "\n",
    "# 6. Mengompilasi model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 7. Melatih model\n",
    "model.fit(X_train, y_train1, epochs=10, batch_size=32, validation_data=(X_test, y_test1))\n",
    "\n",
    "# 8. Evaluasi model\n",
    "loss, accuracy = model.evaluate(X_test, y_test1)\n",
    "print(f'Test accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_classes = (y_pred > 0.5).astype(int).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.80      1871\n",
      "           1       0.80      0.82      0.81      1854\n",
      "\n",
      "    accuracy                           0.81      3725\n",
      "   macro avg       0.81      0.81      0.81      3725\n",
      "weighted avg       0.81      0.81      0.81      3725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(\"Classification Report:\\n\", classification_report(y_test1, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Not Recomeded\n"
     ]
    }
   ],
   "source": [
    "x_rl = [\"This game is very boring, it's better to save your money, friend\"]\n",
    "x_rl_tokenized = tokenizer.texts_to_sequences(x_rl)\n",
    "\n",
    "x_rl_padded = pad_sequences(x_rl_tokenized, maxlen=maxlen)\n",
    "yrl = model.predict(x_rl_padded)\n",
    "yrl_class = (yrl > 0.5).astype(int)\n",
    "if yrl_class == 1:\n",
    "    print('Recommended')\n",
    "elif yrl_class == 0:\n",
    "    print('Not Recomeded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('NLP_Sentiment.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bakso2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
